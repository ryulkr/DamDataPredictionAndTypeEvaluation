import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from bayes_opt import BayesianOptimization
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
import os

# -------------------------------
# ì„¤ì •
# -------------------------------
target_dam = 'ì¶©ì£¼'
data_path = f'./ì˜ˆì¸¡í•  ë°ì´í„°/{target_dam}_GPSë³€ìœ„ê³„(ì˜ˆì¸¡).csv'
save_path = f'./ì˜ˆì¸¡ê²°ê³¼/{target_dam}_XGBoost_Result.csv'

# -------------------------------
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë¶„í• 
# -------------------------------
df = pd.read_csv(data_path, index_col=0, parse_dates=True)
X = df[['AA0001_Y', 'AA0001_Z', 'AA0001_V']]
y = df['AA0001_X']

X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, shuffle=False)  # 0.8 / 0.1 / 0.1

# -------------------------------
# í‰ê°€ í•¨ìˆ˜ (Bayesian Optimizationìš©)
# -------------------------------
def train_xgb_model(max_depth, learning_rate, subsample, colsample_bytree):
    model = XGBRegressor(
        max_depth=int(max_depth),
        learning_rate=learning_rate,
        subsample=subsample,
        colsample_bytree=colsample_bytree,
        n_estimators=500,  # ê³ ì •ëœ ìˆ˜ë¡œ í•™ìŠµ
        objective='reg:squarederror',
        random_state=42
    )
    model.fit(X_train, y_train)  # â† early_stopping ì œê±°
    preds = model.predict(X_val)
    return -mean_absolute_error(y_val, preds)

# -------------------------------
# Bayesian Optimization
# -------------------------------
pbounds = {
    'max_depth': (3, 12),
    'learning_rate': (0.0, 1.0),
    'subsample': (0.0, 1.0),
    'colsample_bytree': (0.0, 1.0)
}

optimizer = BayesianOptimization(f=train_xgb_model, pbounds=pbounds, random_state=42)
optimizer.maximize(init_points=10, n_iter=90)

# -------------------------------
# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
# -------------------------------
params = optimizer.max['params']
best_model = XGBRegressor(
    max_depth=int(params['max_depth']),
    learning_rate=params['learning_rate'],
    subsample=params['subsample'],
    colsample_bytree=params['colsample_bytree'],
    n_estimators=500,
    objective='reg:squarederror',
    random_state=42
)
best_model.fit(X_train_val, y_train_val)
test_preds = best_model.predict(X_test)

# -------------------------------
# ê²°ê³¼ ì €ì¥
# -------------------------------
result_df = pd.DataFrame({
    'Time': X_test.index,
    'Actual': y_test.values,
    'Prediction': test_preds
})
os.makedirs(os.path.dirname(save_path), exist_ok=True)
result_df.to_csv(save_path, index=False)

# -------------------------------
# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥
# -------------------------------
print("\nâœ… ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
for k, v in params.items():
    print(f"{k:<20}: {round(v, 5)}")
print(f"\nğŸ“ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}")
